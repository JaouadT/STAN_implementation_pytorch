{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = torch.randn(1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stem=False, middle=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if stem:\n",
    "            self.conv3x3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same')\n",
    "            self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "        else:\n",
    "            self.conv3x3_1 = nn.Conv2d(in_channels//2, out_channels, kernel_size=3, padding='same')\n",
    "            self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv5x5_1 = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding='same')\n",
    "        self.conv5x5_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1x1_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.conv1x1_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.relu = nn.ReLU(replace=True)\n",
    "\n",
    "        self.down = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.middle = middle\n",
    "\n",
    "    def forward(self, x_branche1, x_branche2):\n",
    "\n",
    "        x1_3 = self.conv3x3_1(x_branche2) # to concat with x5_1\n",
    "        x1_3 = self.relu(x1_3)\n",
    "        x1_3 = self.conv3x3_2(x1_3)\n",
    "        x1_3 = self.relu(x1_3)\n",
    "        skip2 = x1_3\n",
    "        x1_3_down = self.down(skip2)\n",
    "\n",
    "        x1_5 = self.conv5x5_1(x_branche1)\n",
    "        x1_5 = self.relu(x1_5)\n",
    "        x1_5 = self.conv5x5_2(x1_5)\n",
    "        x1_5 = self.relu(x1_5)\n",
    "\n",
    "        x1_1 = self.conv1x1_1(x_branche1)\n",
    "        x1_1 = self.relu(x1_1)\n",
    "        x1_1 = self.conv1x1_2(x1_1)\n",
    "        x1_1 = self.relu(x1_1)\n",
    "\n",
    "        if self.middle:\n",
    "            return torch.cat((x1_5, x1_1, x1_3), 1)\n",
    "\n",
    "        x5_1 = torch.cat((x1_5, x1_1), 1) # for skip connection, to concat with x1_3\n",
    "        \n",
    "        x5_1_down = self.down(x5_1) # for moving to the next encoder\n",
    "\n",
    "        skip1 = torch.cat((x1_3, x5_1), 1) # for skip connection, to concat with x3_3\n",
    "\n",
    "        return skip1, skip2, x1_3_down, x5_1_down\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, filters=[32, 64, 128, 256, 512], n_classes=1):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.n_classes = n_classes\n",
    "        # Decoder 1\n",
    "        self.up1 = nn.ConvTranspose2d(in_channels=self.filters[4]*3, out_channels=self.filters[4], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3x3_1_dec1 = nn.Conv2d(self.filters[3]*3, self.filters[3]*3, kernel_size=3, padding='same')\n",
    "        self.conv3x3_2_dec1 = nn.Conv2d(self.filters[4]*3, self.filters[3], kernel_size=3, padding='same')\n",
    "\n",
    "        # Decoder 2\n",
    "        self.up2 = nn.ConvTranspose2d(in_channels=self.filters[3], out_channels=self.filters[2], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3x3_1_dec2 = nn.Conv2d(self.filters[3], self.filters[3], kernel_size=3, padding='same')\n",
    "        self.conv3x3_2_dec2 = nn.Conv2d(self.filters[2]*5, self.filters[2], kernel_size=3, padding='same')\n",
    "\n",
    "        # Decoder 3\n",
    "        self.up3 = nn.ConvTranspose2d(in_channels=self.filters[2], out_channels=self.filters[1], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3x3_1_dec3 = nn.Conv2d(self.filters[1]*2, self.filters[1], kernel_size=3, padding='same')\n",
    "        self.conv3x3_2_dec3 = nn.Conv2d(self.filters[1]*4, self.filters[1], kernel_size=3, padding='same')\n",
    "\n",
    "        # Decoder 4\n",
    "        self.up4 = nn.ConvTranspose2d(in_channels=self.filters[1], out_channels=self.filters[0], kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3x3_1_dec4 = nn.Conv2d(self.filters[0]*2, self.filters[0], kernel_size=3, padding='same')\n",
    "        self.conv3x3_2_dec4 = nn.Conv2d(self.filters[0]*4, self.n_classes, kernel_size=3, padding='same')\n",
    "\n",
    "        self.relu = nn.ReLU(replace=True)\n",
    "\n",
    "        \n",
    "    def forward(self, x, skip_connections):\n",
    "        \n",
    "        self.skip2_enc4 = skip_connections[0]\n",
    "        self.skip1_enc4 = skip_connections[1]\n",
    "\n",
    "        self.skip2_enc3 = skip_connections[2]\n",
    "        self.skip1_enc3 = skip_connections[3]\n",
    "\n",
    "        self.skip2_enc2 = skip_connections[4]\n",
    "        self.skip1_enc2 = skip_connections[5]\n",
    "\n",
    "        self.skip2_enc1 = skip_connections[6]\n",
    "        self.skip1_enc1 = skip_connections[7]\n",
    "\n",
    "       # Decoder 1\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat((x, self.skip2_enc4), 1)\n",
    "        x = self.conv3x3_1_dec1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.cat((x, self.skip1_enc4), 1)\n",
    "        x = self.conv3x3_2_dec1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Decoder 2\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat((x, self.skip2_enc3), 1)\n",
    "        x = self.conv3x3_1_dec2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.cat((x, self.skip1_enc3), 1)\n",
    "        x = self.conv3x3_2_dec2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Decoder 3\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat((x, self.skip2_enc2), 1)\n",
    "        x = self.conv3x3_1_dec3(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.cat((x, self.skip1_enc2), 1)\n",
    "        x = self.conv3x3_2_dec3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Decoder 4\n",
    "        x = self.up4(x)\n",
    "        x = torch.cat((x, self.skip2_enc1), 1)\n",
    "        x = self.conv3x3_1_dec4(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.cat((x, self.skip1_enc1), 1)\n",
    "        x = self.conv3x3_2_dec4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class STAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Class to build STAN architecture: https://arxiv.org/ftp/arxiv/papers/2002/2002.01034.pdf.\n",
    "    :param in_channels: int, the number of channels of the input image, default is 3\n",
    "    :param n_classes: int, the number of classes of the segmentation task, default is 1\n",
    "    :param filters: list[int], the number of filters for each layer, default is [32, 64, 128, 256, 512]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, n_classes=1):\n",
    "        super(STAN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = Encoder(in_channels, self.filters[0], stem=True)\n",
    "        self.enc2 = Encoder(self.filters[1], self.filters[1])\n",
    "        self.enc3 = Encoder(self.filters[2], self.filters[2])\n",
    "        self.enc4 = Encoder(self.filters[3], self.filters[3])\n",
    "\n",
    "        # Bottleneck (middle)\n",
    "        self.middle = Encoder(self.filters[4], self.filters[4], middle=True)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(filters=self.filters, n_classes=self.n_classes)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        skip1_enc1, skip2_enc1, x3_1_down, x5_1_down = self.enc1(x, x)\n",
    "        skip1_enc2, skip2_enc2, x3_1_down, x5_1_down = self.enc2(x5_1_down, x3_1_down)\n",
    "        skip1_enc3, skip2_enc3, x3_1_down, x5_1_down = self.enc3(x5_1_down, x3_1_down)\n",
    "        skip1_enc4, skip2_enc4, x3_1_down, x5_1_down = self.enc4(x5_1_down, x3_1_down)\n",
    "\n",
    "        x = self.middle(x5_1_down, x3_1_down) # torch.Size([1, 1536, 16, 16])\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.decoder(x, [skip2_enc4, skip1_enc4, skip2_enc3, skip1_enc3, skip2_enc2, skip1_enc2, skip2_enc1, skip1_enc1])\n",
    "\n",
    "        return  x\n",
    "       \n",
    "\n",
    "stan = STAN()\n",
    "x = stan(input_img)\n",
    "print(x.shape)\n",
    "# print(\"middle_x.shape: \", middle_x.shape)\n",
    "# print(\"skip1.shape: \", skip1.shape)\n",
    "# print(\"skip2.shape: \", skip2.shape)\n",
    "# print(\"x1_3_down.shape: \", x1_3_down.shape)\n",
    "# print(\"x5_1_down.shape: \", x5_1_down.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip1.shape:  torch.Size([1, 192, 128, 128])\n",
      "skip2.shape:  torch.Size([1, 64, 128, 128])\n",
      "x1_3_down.shape:  torch.Size([1, 64, 64, 64])\n",
      "x5_1_down.shape:  torch.Size([1, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stem=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if stem:\n",
    "            self.conv3x3_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same')\n",
    "            self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "        else:\n",
    "            self.conv3x3_1 = nn.Conv2d(in_channels//2, out_channels, kernel_size=3, padding='same')\n",
    "            self.conv3x3_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv5x5_1 = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding='same')\n",
    "        self.conv5x5_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1x1_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.conv1x1_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "    def forward(self, x_branche1, x_branche2):\n",
    "\n",
    "        x1_3 = self.conv3x3_1(x_branche2) # to concat with x5_1\n",
    "        x1_3 = self.conv3x3_2(x1_3)\n",
    "        skip2 = x1_3\n",
    "        x1_3_down = self.down(skip2)\n",
    "\n",
    "        x1_5 = self.conv5x5_1(x_branche1)\n",
    "        x1_5 = self.conv5x5_2(x1_5)\n",
    "\n",
    "        x1_1 = self.conv1x1_1(x_branche1)\n",
    "        x1_1 = self.conv1x1_2(x1_1)\n",
    "\n",
    "        x5_1 = torch.cat((x1_5, x1_1), 1) # for skip connection, to concat with x1_3\n",
    "        \n",
    "        x5_1_down = self.down(x5_1) # for moving to the next encoder\n",
    "\n",
    "        skip1 = torch.cat((x1_3, x5_1), 1) # for skip connection, to concat with x3_3\n",
    "\n",
    "        return skip1, skip2, x1_3_down, x5_1_down\n",
    "\n",
    "class STAN(nn.Module):\n",
    "    def __init__(self, in_channels=3, n_classes=1):\n",
    "        super(STAN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "\n",
    "        # encoder 1\n",
    "        self.conv3x3_1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding='same')\n",
    "        self.conv3x3_2 = nn.Conv2d(32, 32, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv5x5_1 = nn.Conv2d(in_channels, 32, kernel_size=5, padding='same')\n",
    "        self.conv5x5_2 = nn.Conv2d(32, 32, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1x1_1 = nn.Conv2d(in_channels, 32, kernel_size=1, padding='same')\n",
    "        self.conv1x1_2 = nn.Conv2d(32, 32, kernel_size=3, padding='same')\n",
    "\n",
    "        # encoder 2\n",
    "        self.conv3x3_1_enc2 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.conv3x3_2_enc2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv5x5_1_enc2 = nn.Conv2d(64, 64, kernel_size=5, padding='same')\n",
    "        self.conv5x5_2_enc2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1x1_1_enc2 = nn.Conv2d(64, 64, kernel_size=1, padding='same')\n",
    "        self.conv1x1_2_enc2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "\n",
    "        self.down = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Run x in the encoder 1:\n",
    "        x1_3 = self.conv3x3_1(x) # to concat with x5_1\n",
    "        x1_3 = self.conv3x3_2(x1_3)\n",
    "        skip2 = x1_3\n",
    "        x1_3_down = self.down(skip2)\n",
    "\n",
    "        x1_5 = self.conv5x5_1(x)\n",
    "        x1_5 = self.conv5x5_2(x1_5)\n",
    "\n",
    "        x1_1 = self.conv1x1_1(x)\n",
    "        x1_1 = self.conv1x1_2(x1_1)\n",
    "\n",
    "        x5_1 = torch.cat((x1_5, x1_1), 1) # for skip connection, to concat with x1_3\n",
    "        \n",
    "        x5_1_down = self.down(x5_1) # for moving to the next encoder\n",
    "\n",
    "        skip1 = torch.cat((x1_3, x5_1), 1) # for skip connection, to concat with x3_3\n",
    "\n",
    "        # Run x in the encoder 2:\n",
    "        x1_3_enc2 = self.conv3x3_1_enc2(x1_3_down) # to concat with x5_1\n",
    "        x1_3_enc2 = self.conv3x3_2_enc2(x1_3_enc2)\n",
    "        skip2_enc2 = x1_3_enc2\n",
    "        x1_3_down_enc2 = self.down(skip2_enc2)\n",
    "\n",
    "        x1_5_enc2 = self.conv5x5_1_enc2(x5_1_down)\n",
    "        x1_5_enc2 = self.conv5x5_2_enc2(x1_5_enc2)\n",
    "\n",
    "        x1_1_enc2 = self.conv1x1_1_enc2(x5_1_down)\n",
    "        x1_1_enc2 = self.conv1x1_2_enc2(x1_1_enc2)\n",
    "\n",
    "        x5_1_enc2 = torch.cat((x1_5_enc2, x1_1_enc2), 1) # for skip connection, to concat with x1_3\n",
    "        \n",
    "        x5_1_down_enc2 = self.down(x5_1_enc2) # for moving to the next encoder\n",
    "\n",
    "        skip1_enc2 = torch.cat((x1_3_enc2, x5_1_enc2), 1) # for skip connection, to concat with x3_3\n",
    "\n",
    "        return skip1_enc2, skip2_enc2, x1_3_down_enc2, x5_1_down_enc2\n",
    "\n",
    "stan = STAN()\n",
    "skip1, skip2, x1_3_down, x5_1_down = stan(input_img)\n",
    "print(\"skip1.shape: \", skip1.shape)\n",
    "print(\"skip2.shape: \", skip2.shape)\n",
    "print(\"x1_3_down.shape: \", x1_3_down.shape)\n",
    "print(\"x5_1_down.shape: \", x5_1_down.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv3_3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same')\n",
    "        self.conv3_3_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.conv5_5 = nn.Conv2d(in_channels, out_channels, kernel_size=5,  padding='same')\n",
    "        self.conv5_1_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x_branche1, x_branche2):\n",
    "        # Branche 1, 5x5\n",
    "        y = self.conv5_5(x_branche2)\n",
    "        x_5x5 = self.conv5_1_3(y)\n",
    "\n",
    "        # Branche 1, 1x1\n",
    "        y = self.conv1_1(x_branche2)\n",
    "        x_1x1 = self.conv5_1_3(y)\n",
    "\n",
    "        # Branche 2, 3x3\n",
    "        x_b_1 = self.conv3_3(x_branche1)\n",
    "        x_3x3_skip = self.conv3_3_3(x_b_1)\n",
    "        \n",
    "        x_concat = torch.cat((x_5x5, x_1x1), 1)\n",
    "        # print(\"x_concat.shape:\", x_concat.shape)\n",
    "\n",
    "        x_branch1_concat_down = self.downsample(x_concat)\n",
    "        # print(\"inp_block_2.shape:\", inp_block_2.shape)\n",
    "\n",
    "        #Concat skip connections\n",
    "        skip_concat = torch.cat((x_concat, x_b_1), 1)\n",
    "\n",
    "        x_branch2_down = self.downsample(x_3x3_skip)\n",
    "\n",
    "        return skip_concat, x_3x3_skip, x_branch1_concat_down, x_branch2_down\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, middle=False):\n",
    "        super().__init__()\n",
    "        self.conv3_3 = nn.Conv2d(in_channels//2, out_channels//2, kernel_size=3, padding='same')\n",
    "        self.conv3_3_3 = nn.Conv2d(out_channels//2, out_channels//2, kernel_size=3, padding='same')\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same')\n",
    "        self.conv5_5 = nn.Conv2d(in_channels, out_channels, kernel_size=5,  padding='same')\n",
    "        self.conv5_1_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same')\n",
    "\n",
    "        self.downsample = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.middle = middle\n",
    "\n",
    "    def forward(self, x_branche1, x_branche2):\n",
    "\n",
    "        print(x_branche1.shape)\n",
    "        print(x_branche2.shape)\n",
    "\n",
    "        # Branche 1, 5x5\n",
    "        y = self.conv5_5(x_branche1)\n",
    "        x_5x5 = self.conv5_1_3(y)\n",
    "\n",
    "        # Branche 1, 1x1\n",
    "        y = self.conv1_1(x_branche1)\n",
    "        x_1x1 = self.conv5_1_3(y)\n",
    "\n",
    "        # Branche 2, 3x3\n",
    "        x_b_2 = self.conv3_3(x_branche2)\n",
    "        x_3x3_skip = self.conv3_3_3(x_b_2)\n",
    "        \n",
    "        if not self.middle:\n",
    "            x_concat = torch.cat((x_5x5, x_1x1), 1)\n",
    "            # print(\"x_concat.shape:\", x_concat.shape)\n",
    "\n",
    "            x_branch1_concat_down = self.downsample(x_concat)\n",
    "            # print(\"inp_block_2.shape:\", inp_block_2.shape)\n",
    "\n",
    "            #Concat skip connections\n",
    "            skip_concat = torch.cat((x_concat, x_b_2), 1)\n",
    "\n",
    "            x_branch2_down = self.downsample(x_3x3_skip)\n",
    "\n",
    "            return skip_concat, x_3x3_skip, x_branch1_concat_down, x_branch2_down\n",
    "\n",
    "        else:\n",
    "            x = torch.cat((x_5x5, x_1x1, x_3x3_skip), 1)\n",
    "            return self.downsample(x)\n",
    "\n",
    "class STAN(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(STAN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.filters = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "        self.encoder1 = StemLayer(self.in_channels, self.filters[0])\n",
    "        self.encoder2 = Encoder(self.filters[1], self.filters[1])\n",
    "        self.encoder3 = Encoder(self.filters[2], self.filters[2])\n",
    "        self.encoder4 = Encoder(self.filters[3], self.filters[3])\n",
    "\n",
    "        self.middle_block = Encoder(self.filters[4], self.filters[4], middle=True)\n",
    "\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.d1_conv1_3x3 = nn.Conv2d(self.filters[4], self.filters[3], kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        skip_concat_enc1, x_3x3_skip_enc1, x_branch1_concat_down, x_branch2_down = self.encoder1(x, x)\n",
    "        print(\"x_branch1_concat_down.shape:\", x_branch1_concat_down.shape)\n",
    "        print(\"x_branch2_down.shape:\", x_branch2_down.shape)\n",
    "\n",
    "        skip_concat_enc2, x_3x3_skip_enc2, x_branch1_concat_down, x_branch2_down = self.encoder2(x_branch1_concat_down, x_branch2_down)\n",
    "        skip_concat_enc3, x_3x3_skip_enc3, x_branch1_concat_down, x_branch2_down = self.encoder3(x_branch1_concat_down, x_branch2_down)\n",
    "        skip_concat_enc4, x_3x3_skip_enc4, x_branch1_concat_down, x_branch2_down = self.encoder4(x_branch1_concat_down, x_branch2_down)\n",
    "        x = self.middle_block(x_branch1_concat_down, x_branch2_down)\n",
    "        print(x.shape)\n",
    "\n",
    "        # middle block\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # middle = torch.cat((x_branch1_concat_down, x_branch2_down), 1)\n",
    "        # print(\"middle.shape:\", middle.shape)\n",
    "\n",
    "        # up1 = self.upsample(middle)\n",
    "        # print(\"up1.shape:\", up1.shape)\n",
    "        # print(\"x_3x3_skip_enc4.shape:\", x_3x3_skip_enc4.shape)\n",
    "        \n",
    "        # d1_1 = torch.cat((up1, x_3x3_skip_enc4), 1)\n",
    "        # print(\"d1_1.shape:\", d1_1.shape)\n",
    "\n",
    "        # d1_1 = self.d1_conv1_3x3(d1_1)\n",
    "        # d1_2 = torch.cat((d1_1, skip_concat_enc4), 1)\n",
    "        # print(\"d1_2.shape:\", d1_2.shape)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Bottleneck shape torch.Size([1, 512, 16, 16])\n",
    "        # print(\"Bottleneck shape\", x_branch2_down.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        return x\n",
    "    \n",
    "stan = STAN()\n",
    "output = stan(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  torch.Size([1, 3, 256, 256])\n",
      "********** Encoder 1 **********\n",
      "e1_out1 torch.Size([1, 32, 128, 128])\n",
      "e1_out2 torch.Size([1, 64, 128, 128])\n",
      "e1_skip1 torch.Size([1, 32, 256, 256])\n",
      "e1_skip2 torch.Size([1, 96, 256, 256])\n",
      "********** Encoder 2 **********\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 192, 128, 128])\n",
      "********** Encoder 3 **********\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 384, 64, 64])\n",
      "********** Encoder 4 **********\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 512, 16, 16])\n",
      "torch.Size([1, 256, 32, 32])\n",
      "torch.Size([1, 768, 32, 32])\n",
      "********** Middle **********\n",
      "torch.Size([1, 1536, 16, 16])\n",
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, input_channels_1, input_channels_2, output_channels):\n",
    "        super(encoder_block, self).__init__()\n",
    "        self.conv5 = nn.Conv2d(in_channels=input_channels_2, out_channels=output_channels, kernel_size=5, padding='same')\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels_2, out_channels=output_channels, kernel_size=1, padding='same')\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=input_channels_1, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1, x_2 = x\n",
    "        # print(\"x_1 : \", x_1.shape)\n",
    "        # print(\"x_2 : \", x_2.shape)\n",
    "\n",
    "        x_2_5 = self.conv5(x_2)\n",
    "        x_2_5 = self.relu(x_2_5)\n",
    "\n",
    "        x_2_1 = self.conv1(x_2)\n",
    "        x_2_1 = self.relu(x_2_1)\n",
    "\n",
    "        x_1_3 = self.conv3_1(x_1)\n",
    "        x_1_3 = self.relu(x_1_3)\n",
    "\n",
    "        # print(\"x_2_5 : \", x_2_5.shape)\n",
    "        # print(\"x_2_1 : \", x_2_1.shape)\n",
    "        # print(\"x_1_3 : \", x_1_3.shape)\n",
    "\n",
    "        # sys.exit(0)\n",
    "\n",
    "        x_2_5_3 = self.conv3_2(x_2_5)\n",
    "        x_2_5_3 = self.relu(x_2_5_3)\n",
    "\n",
    "        x_2_1_3 = self.conv3_2(x_2_1)\n",
    "        x_2_1_3 = self.relu(x_2_1_3)\n",
    "\n",
    "        x_1_3_3 = self.conv3_2(x_1_3)\n",
    "        x_1_3_3 = self.relu(x_1_3_3)\n",
    "\n",
    "        # print(\"x_2_5_3 : \", x_2_5_3.shape)\n",
    "        # print(\"x_2_1_3 : \", x_2_1_3.shape)\n",
    "        # print(\"x_1_3_3 : \", x_1_3_3.shape)\n",
    "\n",
    "        concat = torch.cat((x_2_5_3, x_2_1_3), dim=1)\n",
    "        # print(\"concat : \", concat.shape)\n",
    "\n",
    "        concat_pool = self.maxp(concat)\n",
    "        x_1_3_3_pool = self.maxp(x_1_3_3)\n",
    "        skip1 = x_1_3_3\n",
    "        skip2 = torch.cat((concat, x_1_3), dim=1)\n",
    "\n",
    "        # print(\"out1 : \", x_1_3_3_pool.shape)\n",
    "        # print(\"out2 : \", concat_pool.shape)\n",
    "        # print(\"skip1 : \", skip1.shape)\n",
    "        # print(\"skip2 : \", skip2.shape)\n",
    "\n",
    "        # sys.exit(0)\n",
    "\n",
    "        return x_1_3_3_pool, concat_pool, skip1, skip2\n",
    "\n",
    "class middle_block(nn.Module):\n",
    "    def __init__(self, input_channels_1, input_channels_2, output_channels):\n",
    "        super(middle_block, self).__init__()\n",
    "        self.conv5 = nn.Conv2d(in_channels=input_channels_2, out_channels=output_channels, kernel_size=5, padding='same')\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels_2, out_channels=output_channels, kernel_size=1, padding='same')\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=input_channels_1, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1, x_2 = x\n",
    "        # print(\"x_1 : \", x_1.shape)\n",
    "        # print(\"x_2 : \", x_2.shape)\n",
    "        # 5x5 conv\n",
    "        x_2_5 = self.conv5(x_2)\n",
    "        x_2_5 = self.relu(x_2_5)\n",
    "\n",
    "        # 1x1 conv\n",
    "        x_2_1 = self.conv1(x_2)\n",
    "        x_2_1 = self.relu(x_2_1)\n",
    "\n",
    "        # 3x3 conv\n",
    "        x_1_3 = self.conv3_1(x_1)\n",
    "        x_1_3 = self.relu(x_1_3)\n",
    "\n",
    "        # print(\"x_2_5 : \", x_2_5.shape)\n",
    "        # print(\"x_2_1 : \", x_2_1.shape)\n",
    "        # print(\"x_1_3 : \", x_1_3.shape)\n",
    "\n",
    "        x_2_5_3 = self.conv3_2(x_2_5)\n",
    "        x_2_5_3 = self.relu(x_2_5_3)\n",
    "        x_2_1_3 = self.conv3_2(x_2_1)\n",
    "        x_2_1_3 = self.relu(x_2_1_3)\n",
    "        x_1_3_3 = self.conv3_2(x_1_3)\n",
    "        x_1_3_3 = self.relu(x_1_3_3)\n",
    "        # print(\"x_2_5_3 : \", x_2_5_3.shape)\n",
    "        # print(\"x_2_1_3 : \", x_2_1_3.shape)\n",
    "        # print(\"x_1_3_3 : \", x_1_3_3.shape)\n",
    "        concat = torch.cat((x_2_5_3, x_2_1_3, x_1_3_3), dim=1)\n",
    "        # print(\"concat : \", concat.shape)\n",
    "        return concat\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(decoder_block, self).__init__()\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=output_channels*2, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=output_channels*4, out_channels=output_channels, kernel_size=3, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_t, skip1, skip2 = x\n",
    "        # print(\"x_t : \", x_t.shape)\n",
    "        # print(\"skip1 : \", skip1.shape)\n",
    "        # print(\"skip2 : \", skip2.shape)\n",
    "        x_t_d = self.deconv3(x_t)\n",
    "        # print(\"x_t_d : \", x_t_d.shape)\n",
    "        x_t_d = torch.cat((x_t_d, skip1), dim=1)\n",
    "        # print(\"x_t_d : \", x_t_d.shape)\n",
    "        x_t_d_c = self.conv3_1(x_t_d)\n",
    "        x_t_d_c = self.relu(x_t_d_c)\n",
    "        # print(\"x_t_d_c : \", x_t_d_c.shape)\n",
    "        x_t_d_c = torch.cat((x_t_d_c, skip2), dim=1)\n",
    "        # print(\"x_t_d_c : \", x_t_d_c.shape)\n",
    "        x_t_d_c_c = self.conv3_2(x_t_d_c)\n",
    "        x_t_d_c_c = self.relu(x_t_d_c_c)\n",
    "        # print(\"x_t_d_c_c : \", x_t_d_c_c.shape)\n",
    "\n",
    "        return x_t_d_c_c\n",
    "\n",
    "class stan_architecture(nn.Module):\n",
    "    def __init__(self, initial_channels=3, filters=[32, 64, 128, 256, 512], final_channels=1):\n",
    "        super(stan_architecture, self).__init__()\n",
    "        self.enc1 = encoder_block(initial_channels, initial_channels, filters[0])\n",
    "        self.enc2 = encoder_block(filters[0], filters[1], filters[1])\n",
    "        self.enc3 = encoder_block(filters[1], filters[2], filters[2])\n",
    "        self.enc4 = encoder_block(filters[2], filters[3], filters[3])\n",
    "        self.mid = middle_block(filters[3], filters[4], filters[4])\n",
    "        self.dec4 = decoder_block(filters[4]*3, filters[3])\n",
    "        self.dec3 = decoder_block(filters[3], filters[2])\n",
    "        self.dec2 = decoder_block(filters[2], filters[1])\n",
    "        self.dec1 = decoder_block(filters[1], filters[0])\n",
    "        self.conv = nn.Conv2d(in_channels=filters[0], out_channels=final_channels, kernel_size=3, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_image):\n",
    "        x = input_image\n",
    "        print(\"input: \", x.shape)\n",
    "        print(\"********** Encoder 1 **********\")\n",
    "        e1_out1, e1_out2, e1_skip1, e1_skip2 = self.enc1((x, x))\n",
    "        print(\"e1_out1\", e1_out1.shape)\n",
    "        print(\"e1_out2\", e1_out2.shape)\n",
    "        print(\"e1_skip1\", e1_skip1.shape)\n",
    "        print(\"e1_skip2\", e1_skip2.shape)\n",
    "        print(\"********** Encoder 2 **********\")\n",
    "        e2_out1, e2_out2, e2_skip1, e2_skip2 = self.enc2((e1_out1, e1_out2))\n",
    "        print(e2_out1.shape)\n",
    "        print(e2_out2.shape)\n",
    "        print(e2_skip1.shape)\n",
    "        print(e2_skip2.shape)\n",
    "        print(\"********** Encoder 3 **********\")\n",
    "        e3_out1, e3_out2, e3_skip1, e3_skip2 = self.enc3((e2_out1, e2_out2))\n",
    "        print(e3_out1.shape)\n",
    "        print(e3_out2.shape)\n",
    "        print(e3_skip1.shape)\n",
    "        print(e3_skip2.shape)\n",
    "        print(\"********** Encoder 4 **********\")\n",
    "        e4_out1, e4_out2, e4_skip1, e4_skip2 = self.enc4((e3_out1, e3_out2))\n",
    "        print(e4_out1.shape)\n",
    "        print(e4_out2.shape)\n",
    "        print(e4_skip1.shape)\n",
    "        print(e4_skip2.shape)\n",
    "        print(\"********** Middle **********\")\n",
    "        mid_out = self.mid((e4_out1, e4_out2))\n",
    "        print(mid_out.shape)\n",
    "        # print(\"********** Decoder 4 **********\")\n",
    "        d4_out = self.dec4((mid_out, e4_skip1, e4_skip2))\n",
    "        # print(\"********** Decoder 3 **********\")\n",
    "        d3_out = self.dec3((d4_out, e3_skip1, e3_skip2))\n",
    "        # print(\"********** Decoder 2 **********\")\n",
    "        d2_out = self.dec2((d3_out, e2_skip1, e2_skip2))\n",
    "        # print(\"********** Decoder 1 **********\")\n",
    "        d1_out = self.dec1((d2_out, e1_skip1, e1_skip2))\n",
    "        # print(\"********** Final **********\")\n",
    "        out = self.conv(d1_out)\n",
    "        out = self.relu(out)\n",
    "        # print(d4_out.shape)\n",
    "        # print(d3_out.shape)\n",
    "        # print(d2_out.shape)\n",
    "        # print(d1_out.shape)\n",
    "        # print(\"output : \", out.shape)\n",
    "        return out\n",
    "\n",
    "model = stan_architecture(3, [32, 64, 128, 256, 512], 1)\n",
    "x = torch.randn(1, 3, 256, 256, dtype=torch.float, requires_grad=False)\n",
    "# print(summary(model, (3, 256, 256), batch_size=16))\n",
    "x = model(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ground_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
